## About
Knows everything... except the language. Former math student, currently 'wrestling' with language models (though it's unclear who's winning). PhD candidate at the University of Warsaw.

## Publications

### Planning and Algorithms
#### What Matters in Hierarchical Search for Combinatorial Reasoning Problems?
**Abstract:** This paper explores the effectiveness of subgoal-planning methods in addressing combinatorial reasoning problems, particularly NP-hard tasks. The authors identify key factors that make high-level search strategies advantageous: difficult-to-learn value functions, complex action spaces, the presence of dead ends, and data from diverse experts. The study also introduces a consistent evaluation framework to compare different methods and reassesses current state-of-the-art algorithms, aiming to clarify when and where subgoal methods outperform traditional low-level planners.

**Publication:** [arXiv](https://arxiv.org/abs/2406.03361)

### Language Models
#### When All Options Are Wrong: Evaluating Large Language Model Robustness with Incorrect Multiple-Choice Options
**Abstract:** This paper examines the ability of Large Language Models (LLMs) to identify multiple-choice questions that lack a correct answer, an essential aspect of assessing critical thinking skills. The study finds that LLM performance drops by 55% on average when dealing with such questions. Notably, the Llama 3.1-405B model shows a strong ability to detect the absence of a correct answer, even when instructed to select one. The findings stress the importance of prioritizing critical thinking over rigid instruction-following in LLMs, especially in educational contexts, and establish a benchmark for evaluating critical thinking in these models. The paper also emphasizes the need for better alignment to ensure the responsible use of LLMs in critical applications. 


**Publication:** [research-gate](https://www.researchgate.net/publication/383497377_When_All_Options_Are_Wrong_Evaluating_Large_Language_Model_Robustness_with_Incorrect_Multiple-Choice_Options)

### Vision-Language Models
#### Seeing Through Their Eyes: Evaluating Visual Perspective Taking in Vision Language Models
**Abstract:** This paper addresses the underexplored perspective-taking abilities of vision-language models (VLMs), which are crucial for real-world applications where these models must understand what parts of the environment others can or cannot observe. To investigate this, the authors introduce two manually prepared datasets, Isle-Bricks and Isle-Dots, and benchmark 12 widely used VLMs. The results show a significant performance drop when perspective-taking is required. The study emphasizes the importance of prioritizing perspective-taking in future VLM research and provides a benchmark for testing models on these datasets. 

**Project Website:** [Google Sites](https://sites.google.com/view/perspective-taking/strona-g%C5%82%C3%B3wna)


Explore my work, and feel free to connect if you are interested in collaborative research or discussions in the field of AI.
